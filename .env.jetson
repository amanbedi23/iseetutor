# Jetson-specific environment variables for resource optimization

# Limit model loading
WHISPER_MODEL=tiny  # Use smaller model to reduce memory
LLM_MAX_TOKENS=512  # Limit token generation
LLM_CONTEXT_LENGTH=2048  # Reduce context window

# Disable GPU for certain operations to prevent memory issues
CUDA_VISIBLE_DEVICES=-1  # Disable CUDA temporarily

# Worker limits
CELERY_WORKER_CONCURRENCY=1
UVICORN_WORKERS=1
UVICORN_LIMIT_CONCURRENCY=5

# Memory management
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128
TF_FORCE_GPU_ALLOW_GROWTH=true

# Audio buffer sizes (smaller to reduce memory)
AUDIO_CHUNK_SIZE=1024
AUDIO_SAMPLE_RATE=16000

# Disable non-essential features
ENABLE_VOICE_ACTIVITY_DETECTION=false
ENABLE_KNOWLEDGE_BASE=false
ENABLE_WAKE_WORD=false

# Logging
LOG_LEVEL=WARNING  # Reduce logging overhead